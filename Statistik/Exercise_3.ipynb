{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Marcus Frischherz, Matrikelnummer 08225094\n",
    "# 280412-1 Introduction to Statistics and Data for Astrophycisits\n",
    "## Exercise 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothesis Testing (1)\n",
    "#### a)\n",
    "\n",
    "Null Hypothesis $H_o$: $\\mu = -7.7\\,mag$\n",
    "\n",
    "Alternative Hypothesis $H_a$ : $\\mu \\ne -7.7\\,mag$\n",
    "\n",
    "This implies a two-tailed test. We do not know the $\\sigma$, and want to investigate the mean. This implies, we use the \n",
    "Student's t-Test with the test statistic $T = \\frac{\\bar{X} - \\mu}{S/\\sqrt{n}} $."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b)\n",
    "For large sample sizes (> 30), the t-distribution approaches the normal distribution with $\\sigma = S$. For the normal distribution (Z-distribution) the normalized form is $T = Z = \\frac{\\bar{X} - \\mu_o}{\\sigma \\sqrt{n}} $ . Under $H_o$ this becomes\n",
    "$\\frac{\\bar{X} + 7.7}{\\sigma \\sqrt{n}} $ because $\\mu = -7.7\\,mag$ , see above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c)\n",
    "We can reject $H_o$ when $T_o$ > critical value $T_c$. For a confidence value 5% = 0.05, and a two-tailed test, we have to\n",
    "set up symetric rejection areas at $z < \\alpha / 2$ = 0.025, and $z > (1 - \\alpha / 2 = 0.975)$. Using the z-score table from the lecture 5, checking with z = 0.975 we get the z-score 1.96. So for $|T_o| > 1.96 $ the test statistic will be in the rejection area."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### d)\n",
    "$T_o = \\frac{-7.5 + 7.7}{\\sqrt{1.1} / \\sqrt{148}} = 2.320 $. In the table we find for z=2.320 the value 0.9898\n",
    "\n",
    "As this test is two-tailed, we have to check for $z < \\alpha / 2$ = 0.025, and $z > (1 - \\alpha / 2 = 0.975)$. The z-score is larger. This means, we can reject $H_o$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothesis Testing (2)\n",
    "#### a)\n",
    "Confidence interval definition:\n",
    "$P(\\bar{x} - E ) \\leq \\mu \\leq \\bar{x} + E) = 1 - \\alpha$\n",
    "\n",
    "$T = \\frac{\\bar{x} - \\mu}{S/\\sqrt{n}} \\approx t_{n-1}$ for n-1 degrees of freedom\n",
    "\n",
    "We use again the approximation of a standard normal distribution.\n",
    "\n",
    "$P(-t_{\\alpha/2} \\leq \\frac{\\bar{x} - \\mu}{S/\\sqrt{n}} \\leq t_{\\alpha/2}) = 1 - \\alpha $\n",
    "\n",
    "By re-arranging we get:\n",
    "\n",
    "$P(\\bar{x} - t_{\\alpha/2} \\cdot \\frac{S}{\\sqrt{n}} \\leq \\mu \\leq \\bar{x} + t_{\\alpha/2} \\cdot \\frac{S}{\\sqrt{n}}) = 1 - \\alpha$\n",
    "\n",
    "With the z-score for 1.96 being 0.975 we arrive at the wanted expression\n",
    "\n",
    "$CI = (\\bar{x} - 1.96 \\cdot \\frac{S}{\\sqrt{n}}, \\bar{x} + 1.96 \\cdot \\frac{S}{\\sqrt{n}} ) $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b)\n",
    "$CI = (-7.5 \\pm 1.96 \\frac{\\sqrt{1.1}}{\\sqrt{148}}) = (-7.5 \\pm 0.169) = (-7.669, -7.331)$\n",
    "The $\\mu_o$ from the $H_o$ is outside. This means, the difference between $H_a$ and $H_o$ is significant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c)\n",
    "$p = 2 \\cdot P(T \\geq |T_o|) $\n",
    "\n",
    "$T_o = \\frac{\\bar{x} - \\mu_o}{S/\\sqrt{n}} = \\frac{ -7.5 + 7.7}{\\sqrt{1.1}/\\sqrt{148}} = 2.32$\n",
    "\n",
    "$P(T \\leq 2.32)$ using again the standard normal distribution gives us 0.9898, so we get\n",
    "\n",
    "$p = 2 \\cdot [1 - P(T \\leq |T_o|)] = 0.0204 $ \n",
    "\n",
    "The p-value is less than the chosen confidence 0.05, hence we can reject $H_o$ ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothesis Testing (3)\n",
    "#### a)\n",
    "See below for the Python script importing the data file (which I reformatted to contain commas as seperators), and summing up, and normalizing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     mJy   G   R  Cum_G  Cum_R        Sm        Sn       Dmn\n",
      "0  -15.0   0   0      0      0  0.000000  0.000000  0.000000\n",
      "1  -14.0   0   0      0      0  0.000000  0.000000  0.000000\n",
      "2  -13.0   1   0      1      0  0.002591  0.000000  0.002591\n",
      "3  -12.0   2   0      3      0  0.007772  0.000000  0.007772\n",
      "4  -11.0   5   0      8      0  0.020725  0.000000  0.020725\n",
      "5  -10.0   7   3     15      3  0.038860  0.010345  0.028515\n",
      "6   -9.0   2   6     17      9  0.044041  0.031034  0.013007\n",
      "7   -8.0  11   2     28     11  0.072539  0.037931  0.034608\n",
      "8   -7.0  11   6     39     17  0.101036  0.058621  0.042416\n",
      "9   -6.0   7  11     46     28  0.119171  0.096552  0.022619\n",
      "10  -5.0  13  12     59     40  0.152850  0.137931  0.014919\n",
      "11  -4.0  11  18     70     58  0.181347  0.200000  0.018653\n",
      "12  -3.0  25  19     95     77  0.246114  0.265517  0.019403\n",
      "13  -2.0  39  23    134    100  0.347150  0.344828  0.002323\n",
      "14  -1.0  31  20    165    120  0.427461  0.413793  0.013668\n",
      "15   0.0  32  25    197    145  0.510363  0.500000  0.010363\n",
      "16   1.0  37  27    234    172  0.606218  0.593103  0.013114\n",
      "17   2.0  22  27    256    199  0.663212  0.686207  0.022994\n",
      "18   3.0  31  23    287    222  0.743523  0.765517  0.021994\n",
      "19   4.0  23  22    310    244  0.803109  0.841379  0.038271\n",
      "20   5.0  21  11    331    255  0.857513  0.879310  0.021797\n",
      "21   6.0  11  16    342    271  0.886010  0.934483  0.048472\n",
      "22   7.0   6  10    348    281  0.901554  0.968966  0.067411\n",
      "23   8.0  16   0    364    281  0.943005  0.968966  0.025960\n",
      "24   9.0   4   0    368    281  0.953368  0.968966  0.015598\n",
      "25  10.0   6   5    374    286  0.968912  0.986207  0.017295\n",
      "26  11.0   4   0    378    286  0.979275  0.986207  0.006932\n",
      "27  12.0   2   4    380    290  0.984456  1.000000  0.015544\n",
      "28  13.0   6   0    386    290  1.000000  1.000000  0.000000\n",
      "29  14.0   0   0    386    290  1.000000  1.000000  0.000000\n",
      "30  15.0   0   0    386    290  1.000000  1.000000  0.000000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "fluxes = pd.read_csv('RadioFluxes.dat')\n",
    "\n",
    "fluxes['Cum_G'] = fluxes['G'].cumsum()\n",
    "fluxes['Cum_R'] = fluxes['R'].cumsum()\n",
    "fluxes['Sm'] = fluxes['Cum_G'] / fluxes['Cum_G'].max()\n",
    "fluxes['Sn'] = fluxes['Cum_R'] / fluxes['Cum_R'].max()\n",
    "fluxes['Dmn'] = abs(fluxes['Sm'] - fluxes['Sn'])\n",
    "\n",
    "print(fluxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    mJy  G   R  Cum_G  Cum_R        Sm        Sn       Dmn\n",
      "22  7.0  6  10    348    281  0.901554  0.968966  0.067411\n"
     ]
    }
   ],
   "source": [
    "maxDid = fluxes['Dmn'].idxmax()\n",
    "\n",
    "print(fluxes.loc[maxDid:maxDid])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b)\n",
    "The $H_o$ hypothesis is: 'G' sample does not contain excessive flux compare with the 'R' sample\n",
    "\n",
    "The alternative hypothesis $H_a$ 'G' sample does contain more flux compared with the 'R' sample\n",
    "\n",
    "This is a one sided test (we are comparing only for flux(G) > flux(R)). n=386 and m=290 are much larger than 35, so we can use the $\\chi^2$ approximation $4D^2_{m,n} \\frac{mn}{m + n} $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "factor: 165.6\n",
      "chi-squared: 3.01\n"
     ]
    }
   ],
   "source": [
    "m = 290\n",
    "n = 386\n",
    "factor = (m * n) / (m + n)\n",
    "print (f'factor: {factor:.1f}')\n",
    "\n",
    "chisqrd = 4 * D * D * factor\n",
    "print(f'chi-squared: {chisqrd:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Significance: 0.990, Chi-squared: 0.0201\n",
      "Significance: 0.980, Chi-squared: 0.0404\n",
      "Significance: 0.950, Chi-squared: 0.1026\n",
      "Significance: 0.900, Chi-squared: 0.2107\n",
      "Significance: 0.800, Chi-squared: 0.4463\n",
      "Significance: 0.700, Chi-squared: 0.7133\n",
      "Significance: 0.500, Chi-squared: 1.3863\n",
      "Significance: 0.300, Chi-squared: 2.4079\n",
      "Significance: 0.200, Chi-squared: 3.2189\n",
      "Significance: 0.100, Chi-squared: 4.6052\n",
      "Significance: 0.050, Chi-squared: 5.9915\n",
      "Significance: 0.025, Chi-squared: 7.3778\n",
      "Significance: 0.020, Chi-squared: 7.8240\n",
      "Significance: 0.010, Chi-squared: 9.2103\n",
      "Significance: 0.001, Chi-squared: 13.8155\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats\n",
    "import numpy as np\n",
    "\n",
    "def chi2_values(df, alphas):\n",
    "    return [scipy.stats.chi2.ppf(1 - alpha, df) for alpha in alphas]\n",
    "\n",
    "# Signifikanzniveaus\n",
    "alphas = [0.99, 0.98, 0.95, 0.9, 0.8, 0.7, 0.5, 0.3, 0.2, 0.1, 0.05, 0.025, 0.02, 0.01, 0.001]\n",
    "# degrees of freedom\n",
    "n = 2  \n",
    "\n",
    "chi2_vals = chi2_values(n, alphas)\n",
    "\n",
    "# Ausgabe der Ergebnisse\n",
    "for alpha, chi2_val in zip(alphas, chi2_vals):\n",
    "    print(f\"Significance: {alpha:.3f}, Chi-squared: {chi2_val:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I notice, that the table in the lecture note contains an error: in the top line, where the significance level is listed, it should be 0.7 instead of 0.8. I checked this also for some other degrees of freedom.\n",
    "\n",
    "Comparing the calculated test statistic value = 3 from above with $\\chi^2$ for 2 degees of freedom, we see that we can only reject $H_0$ at significance levels < 20%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c)\n",
    "\n",
    "For the question, whether Flux(G) != Flux(R), which is the same as saying Flux(G) < Flux(R) OR Flux(G) > Flux(R), this is the definition of a two-tailed test. Taking 5% significance value means $\\frac{\\alpha}{2} = 0.025$. This gives a $\\chi^2 = 7.38$.\n",
    "\n",
    "Taking above formula \n",
    "$4D^2_{m,n} \\frac{mn}{m + n} = \\chi^2$ we can convert to $ D_{m,n} = \\sqrt{\\chi^2 \\frac{m + n}{4 mn}} $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chi2: 7.3778\n",
      "D_mn minimum: 0.10554\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.stats\n",
    "\n",
    "m = 290\n",
    "n = 386\n",
    "alpha = 0.05\n",
    "\n",
    "chisqrd = scipy.stats.chi2.ppf(1 - alpha / 2, 2)\n",
    "print(f'chi2: {chisqrd:.4f}')\n",
    "D_mn = np.sqrt(chisqrd * (m + n) / (4 * m * n))\n",
    "print (f'D_mn minimum: {D_mn:.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$D_{m,n}$ should be greater than 0.10554."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
